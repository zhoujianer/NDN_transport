<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with LaTeX2HTML 2008 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>A smart explicitness congestion notification transport control mechanism for NDN</TITLE>
<META NAME="description" CONTENT="A smart explicitness congestion notification transport control mechanism for NDN">
<META NAME="keywords" CONTENT="main">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2008">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="main.css">

</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<IMG WIDTH="81" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next_inactive"
 SRC="/usr/share/latex2html/icons/nx_grp_g.png"> 
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="/usr/share/latex2html/icons/up_g.png"> 
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="/usr/share/latex2html/icons/prev_g.png">   
<BR>
<BR><BR></DIV>
<!--End of Navigation Panel-->

<P>

<P>
<H1 ALIGN=CENTER>A smart explicitness congestion notification transport control mechanism for NDN</H1>
<P ALIGN=CENTER><STRONG>Jianer Zhou12,
Zhenyu Li1,
Qinghua Wu12,
Yonggong Wang12,
Gaogang Xie1
1Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China</STRONG>
<BR><I>
{zhoujianer, zyli, wuqinghua, wangyonggong, xieg}@ict.ac.cn
2Graduate School of Chinese Academy of Sciences, Beijing, China</I>
</P>
<HR>

<P>

<H3>Abstract:</H3>
<DIV CLASS="ABSTRACT">
Named Data Network(NDN) is a new Internet architecture. Its changes of the network layer also shed light on the transport layer. The Data coming back along the same path of the Interest natively acts as a barrier of the Explicit Congestion Notification (ECN) information to receiver.  Avoiding a congesting path can be achieved by adaptive forwarding which is a main feature of the NDN data plane. In this paper we implement an ECN transport mechanism in NDN, using the Data to carry ECN information. And we make use of network-wide information of the SDN controller  to design smart forwarding mechanism. Our simulation in ndnSim shows that the ECN transport mechanism out-performance TCP-style NDN transport mechanisms in link utilization, packet dropping and flow complete time. The network-view information of the SDN controller can optimize the adaptive forwarding in NDN. By joining the ECN congestion mechanism and smart forwarding, the total flow complete time can be reduced.

<P>
<SPAN  CLASS="textit">Index Terms</SPAN>-NDN, Transport mechanism, ECN, Congestion control, Adaptive forwarding
</DIV>
<P>

<P>

<P>

<P>

<H1><A NAME="SECTION00010000000000000000">
Introduction</A>
</H1>
People now using network care more about ``what" they can get from network. However TCP/IP, the network architecture of Internet, is initially designed based on the principle of ``where" to connect the users. This mismatch between the user-demand and network-principle makes the network difficult to satisfy the users. To overcome this, some clean-state network architecture have been proposed. NDN is one of such clean-state architecture[<A
 HREF="main.html#NDN">1</A>].In NDN, users just send Interest into the network, and the network will return the corresponding Data to it, unnecessary to care about where to get the Data.

<P>
As the NDN network layer is still based on the best-effort transmit model, it is necessary to use transport control to guarantee effective transfer. Some TCP-style transport control mechanisms have been proposed for NDN, such ICP[<A
 HREF="main.html#ICP">2</A>], CCTCP[<A
 HREF="main.html#CCTCP">4</A>] and HR-ICP[<A
 HREF="main.html#shape">5</A>]. However these TCP-style transport mechanisms in NDN still have same problems as TCP/IP, such as low link utilization, and high packets dropping rate. Explicit congestion notification(ECN) is a promise way to achieve high link utilization[<A
 HREF="main.html#XCP">7</A>] . Adaptive forwarding is a new feature of the NDN[<A
 HREF="main.html#Adaptive">3</A>]. Adaptive forwarding let router choose a suitable path according the network situation. If the router sense the link has been congested, then it can choose another path. It is completely different with TCP/IP, as in TCP/IP the forwarding process is strictly followed the route table. By make use of the adaptive forwarding, router can deal with the network congestion quickly.

<P>
But by now, as what we have known, there is not ECN-style congestion mechanism proposed in NDN and there is little research about the congestion avoiding mechanism making use of the adaptive forwarding. In this paper we use the Data(which come back along the same way of Interest) to carry the ECN information, and design an ECN transport mechanism for NDN. We also make use of the SDN's network-wide information to choose a suitable forwarding interface[<A
 HREF="main.html#SDN">6</A>]. Joining the ECN and smart-adaptive forwarding mechanism, we can not only improve single link bandwidth utilization but also the whole network resource utilization. Summary, our main contributions are:
<DL COMPACT>
<DT>1.</DT>
<DD>First achieve an ECN transport mechanism in NDN.

<P>
</DD>
<DT>2.</DT>
<DD>First use SDN-style control information to design smart forwarding mechanism to ultimately use the whole network resource.

<P>
</DD>
<DT>3.</DT>
<DD>Packet-level simulation shows that joining ECN and smart forwarding in NDN can improve link utilization and the total flow complete time.
</DD>
</DL>
The rest of the paper is organized as followed: in Sec. 2 we will introduce the NDN's feature that we will use to design our transport mechanism. In Sec. 3 we will discuss the design rationale. In Sec. 4 we will introduce the ECN congestion mechanism and the SDN-style smart forwarding. In Sec. 5, we demonstrate the effectiveness of our mechanism. In Sec. 6, we will introduce related work. Finally Sec. 7 concludes the paper.

<P>

<P>

<H1><A NAME="SECTION00020000000000000000">
Background</A>
</H1>
We recall come features of NDN that we will use to design our transport mechanism. The full description of NDN can be found in NDN paper[<A
 HREF="main.html#NDN">1</A>][<A
 HREF="main.html#Adaptive">3</A>].

<P>
Data feedback. In NDN, consumers send Interest to request Data. The router uses Content Store, Pending Interest Table(PIT) and Forwarding Information Base(FIB) to return , record and forward the Interest respectively. For every consumer, one Interest pull back exactly one Data. As the PIT maintains every Interest's state, such as the coming and leaving entry, the Data will come back along exactly the same path with Interest. Such ``same path" feedback let the Data natively act as carrier to bring back the ECN information to consumers.

<P>
Adaptive forwarding. Adaptive forwarding is a main feature of NDN data plain. In TCP/IP, forwarding table completely follows the route table without any adaptability, and there is just one path to the destination in the route table. However in NDN, during the forwarding process, router can adaptively choose a forwarding interface from several available paths according the network situation. In [<A
 HREF="main.html#Adaptive">3</A>] Cheng, etc. make use of the adaptive forwarding mechanism to design a hop-by-hop congestion control mechanism. Routers adaptively forward the Interest to another interface (if available) when it detects that the next hop has been congested. Such adaptive forwarding way helps the network solve congestion much easier than the route assistant congestion in TCP/IP, because the route-assistant congestion mechanism needs the help of route protocol[<A
 HREF="main.html#selfish">10</A>]. However such just one hop detection is not enough if the congestion happens on later link, because the one hop detection cannot sense it.  SDN-style solution can get the network-wide information. And such network-wide information is a promise way to overcome the limit of the just one hop information.

<P>

<H1><A NAME="SECTION00030000000000000000">
Design rationale</A>
</H1>
When we initially think about the transport control mechanism in new network architecture, the first question is who dominant and should be responsible for the congestion control? In TCP/IP, as its push principle, it is the senders who deal with the network congestion by changing the packet sending window. Under the pull nature of NDN, it is obviously that the receivers should be responsible for the network congestion. The one-Interest one-Data principle makes it possible to control the network traffic through the control of Interest sending rate. Such control congestion is called receiver-driven transport mechanism[<A
 HREF="main.html#Contug">15</A>]. Our design also follows the receiver-driven principle.

<P>
If several flows share one link, it is ideal that the link bandwidth is ultimately used and at the same time fairly shared by all the flows. ECN information reflects the network resource situation such as that the available bandwidth and flow number of the path. By the ECN information, receivers can adjust its Interest sending rate to ultimately use the bandwidth and achieve fairness. So our first design goal is to use the ECN information to control the receiver's Interest sending rate.

<P>
By controlling the receiver's Interest sending rate, we can perhaps ultimately use the link bandwidth and avoid congestion. But if all the flows choose a path that goes through the same bottleneck, even we can ultimately use the link bandwidth, the flow complete time can be low, because too many flows share the same bottleneck. So if there are several paths available for the flows, how can we choose different paths for different flows that minimum all the flows' complete time? Our second design goal is to design a smart forwarding mechanism that minimum flow complete time.

<P>
In TCP/IP, the route path is single path, and the forwarding process is strictly follows the route path. Choosing path adaptively is very difficult. However, in NDN, the adaptive forwarding makes it possible. Take the mesh network topology in Fig. <A HREF="#fig-topology"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. as example. A flow goes through router5. The flow has two available paths to get the data from provider. Router5 can easily measure the congestion condition at the link1 (between router5-7) and link2 (between router5-8). If the router senses that link1 is much more congested than link2 then the router can adaptively forward the flow to link2. By such adaptive forwarding, the network resource can be effectively used and reduce the flow complete time.

<P>
But such just one hop measure way is very limited. Take the same situation as example. The true bottleneck happens on link3 (between router10-13). But the router5 can measure just one hop situation, it cannot sense the true bottleneck is on the link3, so it will still forward the interest to link2. The wrong forwarding decision will add more burdens to link3, and reduce the flow complete time of all the flows.

<P>
The SDN-style controller can get the whole network information. We will introduce the SDN's network-wide information to overcome the ¡°limited information¡± problem. By the network-view information, the Interest can be forwarded to the best path. The whole network bandwidth utilization and total flow complete time can be improved.

<P>

<H1><A NAME="SECTION00040000000000000000">
Design</A>
</H1>
To achieve the two goals above, our design divided into three parts. First we design the ECN Interest sending rate on the receiver. Second we design a smart forwarding mechanism and at last we analysis the convergence and stability of the system.

<P>

<H2><A NAME="SECTION00041000000000000000">
ECN Interest sending rate</A>
</H2>
Our motivation is to send Interest at a maximum rate that the path can handle the corresponding coming back Data without dropping. To achieve this, every router on the path should calculates each flow's maximum Interest sending rate that it can handle, without causing congestion. We define such maximum rate as <SPAN  CLASS="textit">R(t)</SPAN>.

<P>
Fig.<A HREF="#fig-header"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows the Interest and Data'ECN header. The ECN header contains the explicit congestion notification information on the path. The Interest carries the RTT of the flow. The RTT is defined as the interval between the receiver sends an Interest to the receiver receives the corresponding Data. In our design, RTT is used to determine the <SPAN  CLASS="textit">R(t)</SPAN>'s updating interval. The provider copied the Interest's RTT to Data when it send back the Data, and the routers do not change it along the path. The router compares the <SPAN  CLASS="textit">R(t)</SPAN> that is recorded in the Data with its own  <SPAN  CLASS="textit">R(t)</SPAN>. If the router's rate is smaller, it replaces it. By this way, the coming back Data carries the minimum  <SPAN  CLASS="textit">R(t)</SPAN> of all the routers along the path. As the Data comes back along the same path of the Interest, the rate on the Data also reflects the path of the Interest. Each receiver sends its Interest according the  <SPAN  CLASS="textit">R(t)</SPAN> it receives from the Data.

<P>

<DIV ALIGN="CENTER"><A NAME="fig-header"></A><A NAME="127"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Explicit congestion notification header for Interest and Data.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV>
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

 Suppose we know how many flows going through a link, and we want to share its bandwidth with all the flows, then <SPAN  CLASS="textit">R(t)</SPAN> can be calculated as follow:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
R(t)=\frac{C}{Flow_{num}*Size_{d}}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="178" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$\displaystyle R(t)=\frac{C}{Flow_{num}*Size_{d}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">1</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
<!-- MATH
 $\emph{Size}_{\emph{d}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="36" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ \emph{Size}_{\emph{d}}$"></SPAN> is the size of incoming Data. <!-- MATH
 $\emph{Flow}_{\emph{num}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="57" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img4.png"
 ALT="$ \emph{Flow}_{\emph{num}}$"></SPAN> is the flow number on the link. Eq. 1 is the ideal situation. When the network condition changes, such as the number of flows changes, <SPAN  CLASS="textit">R(t)</SPAN> should update. To make the update reasonable and let the system enter stable situation, Eq. 1 should evolve as:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
R(t)=R(t-RTT_{avg})+\frac{\alpha(C-S(t))-\beta\frac{Q(t)}{RTT_{avg}}}{Flow_{num}*Size_{d}}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="344" HEIGHT="70" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.png"
 ALT="$\displaystyle R(t)=R(t-RTT_{avg})+\frac{\alpha(C-S(t))-\beta\frac{Q(t)}{RTT_{avg}}}{Flow_{num}*Size_{d}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">2</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
<SPAN  CLASS="textit">R(t)</SPAN> is the Interest sending rate that the router assigns to all flows at time <SPAN  CLASS="textit">t</SPAN>. <SPAN  CLASS="textit">C</SPAN> is the bandwidth of the link. <SPAN  CLASS="textit">S(t)</SPAN> is the speed of coming back Data. <SPAN  CLASS="textit">Q(t)</SPAN> is the packets that occupied in the queue at time t.  <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> is the parameters that influence the convergence and performance.  <!-- MATH
 $\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ \emph{RTT}_{\emph{avg}}$"></SPAN> is the average RTT of all the flows that go through this router. We set <!-- MATH
 $\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ \emph{RTT}_{\emph{avg}}$"></SPAN> as <SPAN  CLASS="textit">R(t)</SPAN>'s updating interval.

<P>
The reason we define the R(t) as Eq.2 is easy to understand. The available bandwidth and queue should be fairly share by all the flows, so the link's available resource is divided by the number of flow. If <!-- MATH
 $\emph{(C-S(t))}>0$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="83" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img9.png"
 ALT="$ \emph{(C-S(t))}&gt;0$"></SPAN>, there are more available bandwidth to be used and the rate should be increased. Otherwise, the bandwidth has been over used and the sending rate should be reduced. We assume that the packets occupied in the queue should always come to zero. If it is not zero, it means too many Datas flow into this link, and the Interest sending rate should be reduced. In every <!-- MATH
 $\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ \emph{RTT}_{\emph{avg}}$"></SPAN> the router should drain <!-- MATH
 $\emph{Q(t)}/\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="83" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img10.png"
 ALT="$ \emph{Q(t)}/\emph{RTT}_{\emph{avg}}$"></SPAN> data. Because the R(t) is the Interest sending rate, and the available resource is supplied to the Data, so we divide it by the size of Data.

<P>
If the router want to make the system converse to stable stage more quickly, it can update the R(t) with shorter interval T <!-- MATH
 $(0<T\leq\emph{RTT}_{\emph{avg}})$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="123" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img11.png"
 ALT="$ (0&lt;T\leq\emph{RTT}_{\emph{avg}})$"></SPAN>. Then  Eq. 2 becomes:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
R(t)=R(t-T)+\frac{\frac{T}{RTT_{avg}}\ast(\alpha(C-S(t))-\beta\frac{Q(t)}{RTT_{avg}})}{Flow_{num}*Size_{d}}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="378" HEIGHT="70" ALIGN="MIDDLE" BORDER="0"
 SRC="img12.png"
 ALT="$\displaystyle R(t)=R(t-T)+\frac{\frac{T}{RTT_{avg}}\ast(\alpha(C-S(t))-\beta\frac{Q(t)}{RTT_{avg}})}{Flow_{num}*Size_{d}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">3</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Using the prefix of the Interest name to estimate how many flows go through the router will add complexity to the router. In[<A
 HREF="main.html#RCP">8</A>], it has been proved that the processor-fair resource allocated way can estimate the flow number by the each flow's sending rate. Processor-fair means routers fairly give the link bandwidth and queue resource to all flows of this link. So we also use process-fair way to calculate how many flows go through this link:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
Flow_{num}=\frac{C}{R(t-RTT_{avg})\ast{Size_{d}}}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="251" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img13.png"
 ALT="$\displaystyle Flow_{num}=\frac{C}{R(t-RTT_{avg})\ast{Size_{d}}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">4</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
As we set every flow share the link bandwidth equally, and every flow's rate is the same, it is reasonable to use Eq. 4 to estimate the number of flows. In Sec. 5, we will prove that the estimation is correctly.
Joining Eq.3 and Eq.4, Eq.3 becomes:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
R(t)=R(t-T)[1+\frac{\frac{T}{RTT_{avg}}\ast(\alpha(C-S(t))-\beta\frac{Q(t)}{RTT_{avg}})}{C}]
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="395" HEIGHT="70" ALIGN="MIDDLE" BORDER="0"
 SRC="img14.png"
 ALT="$\displaystyle R(t)=R(t-T)[1+\frac{\frac{T}{RTT_{avg}}\ast(\alpha(C-S(t))-\beta\frac{Q(t)}{RTT_{avg}})}{C}]$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">5</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
Many factors may influence the size of Data in NDN, such as the different MTU of different link. So it will be very difficult to exactly measure the size of Data. When we need to use the size of Data to test the the accuracy of the flow number estimation, we have to use the historical information to estimate the size of Data. From Eq. 5 we can find that, R(t) do not need to measure the flow number directly and the size of Data. That will greatly simplify the router's calculating process.

<P>
Although our Interest sending rate's design principle is similar with RCP[<A
 HREF="main.html#RCP">8</A>], our design process is different. In this paper we use <SPAN  CLASS="textit">R(t)</SPAN> to control the receiver's sending rate, but RCP use the <SPAN  CLASS="textit">R(t)</SPAN> to control the sender's packet sending rate. We also have to consider the size of Data, and in RCP the packet's size has not relationship with the design process.

<H2><A NAME="SECTION00042000000000000000">
Smart adaptive forwarding</A>
</H2>
In this paper we just control the forwarding process, not the route calculating process. The route algorithm in NDN is on active research, and it is still uncomplete. But from the algorithms proposed by now, we can see that the NDN route algorithm is different from TCP/IP[<A
 HREF="main.html#ndnroute">11</A>]. Traditional route protocol such as OSPF and RIP just have one single path for each destination. But in NDN, a data may be placed on different places, so there may be several paths to get a data. And even the data from the same provider may have different available paths. In this paper, we assume the receivers have several paths to get a data, and the routers have known every hop of different paths. The Smart adaptive forwarding mechanism we proposed just has relationship with the choose of forwarding interfaces from different paths.

<P>
Every router sends its own <SPAN  CLASS="textit">R(t)</SPAN>, the transmit delay and the bandwidth of the next hop to the controller at an interval of <!-- MATH
 $\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ \emph{RTT}_{\emph{avg}}$"></SPAN>. After several <!-- MATH
 $\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ \emph{RTT}_{\emph{avg}}$"></SPAN>, the controller can know every router's <SPAN  CLASS="textit">R(t)</SPAN> and the transmit delay of every hop. We call the information as forwarding-assistant information. The network's route information can also be stored in the controller. By the forwarding-assistant information and route information, we can calculate the best forwarding strategy. The forwarding-assistant and route information stored in the controller is showed in Fig.<A HREF="#fig-assistant-information"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>.

<P>

<DIV ALIGN="CENTER"><A NAME="fig-assistant-information"></A><A NAME="203"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Forwarding assistant and route information stored in the controller.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV>
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
Using the Interest sending rate we propose above, the FCT of each flow is:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
FCT=\frac{Size_{f}}{Size_{d}\ast{R_{b}}}+RTT
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="193" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img16.png"
 ALT="$\displaystyle FCT=\frac{Size_{f}}{Size_{d}\ast{R_{b}}}+RTT$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">6</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
<!-- MATH
 $\emph{Size}_{\emph{f}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img17.png"
 ALT="$ \emph{Size}_{\emph{f}}$"></SPAN> is the size of the flow. <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img18.png"
 ALT="$ R_{b}$"></SPAN> is the bottleneck's Interest sending rate. <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img18.png"
 ALT="$ R_{b}$"></SPAN> can be easily calculated by the forwarding-assistance and route information. Eq. 6 means that the FCT is the time that the flow goes through the bottleneck plus the RTT of this flow. The RTT of this flow can be calculated by the forwarding-assistant information.
We suppose flow i has serval available paths. If it chooses path j, then this flow's FCT on path j should be:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
FCT_{i,j}=\frac{Size_{f}}{Size_{d}\ast{R^{'}_{b}}}+RTT_j
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="210" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img19.png"
 ALT="$\displaystyle FCT_{i,j}=\frac{Size_{f}}{Size_{d}\ast{R^{'}_{b}}}+RTT_j$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">7</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
Where <SPAN CLASS="MATH"><IMG
 WIDTH="44" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.png"
 ALT="$ RTT_j$"></SPAN> is the RTT of flow i if it chooses path j and <!-- MATH
 $R^{'}_{bottleneck}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="75" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img21.png"
 ALT="$ R^{'}_{bottleneck}$"></SPAN> is the bottleneck's Interest sending rate on path j.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
R^{'}_{b}=\frac{C}{Flow_{num}+1}
=\frac{C}{C/(R_{b}\ast{Size_{d}})+1}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="297" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img22.png"
 ALT="$\displaystyle R^{'}_{b}=\frac{C}{Flow_{num}+1} =\frac{C}{C/(R_{b}\ast{Size_{d}})+1}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">8</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
For simplify, we set the value of <SPAN CLASS="MATH"><IMG
 WIDTH="43" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img23.png"
 ALT="$ Size_{d}$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="44" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img24.png"
 ALT="$ Size_{f}$"></SPAN> as fixed values, and suppose <!-- MATH
 $Size_{data} =Size_{flow}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="143" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$ Size_{data} =Size_{flow}$"></SPAN>. So Eq.7 becomes:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
FCT_{i,j}=\frac{C/(R_{b}*Size_{d})+1}{C}+RTT_j
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="270" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img26.png"
 ALT="$\displaystyle FCT_{i,j}=\frac{C/(R_{b}*Size_{d})+1}{C}+RTT_j$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="eqn-number">9</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
Our design goal is to minimum the Total Flow Complete Time (TFCT) in the network. TFCT is the sum of all the flows' complete time. To achieve our goal we define the objective of the smart forwarding as:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{aligned}
& \min &&  \sum_{i=0}^{n} FCT_i \\
& \text{s.t.}  && \text{path } j \text{ is available};\\
&              && \forall i, P_i \in \{0,1\};\\
&              && \max \min  R_i \enspace .
\end{aligned}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="167" HEIGHT="128" BORDER="0"
 SRC="img27.png"
 ALT="\begin{equation*}\begin{aligned}&amp; \min &amp;&amp; \sum_{i=0}^{n} FCT_i \\ &amp; \text{s.t.} ...
...i, P_i \in \{0,1\};\\ &amp; &amp;&amp; \max \min R_i \enspace . \end{aligned}\end{equation*}"></SPAN></TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img28.png"
 ALT="$ P_i$"></SPAN> is the number of path that flow i chooses. <!-- MATH
 $P_i \in \{0,1\}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="78" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img29.png"
 ALT="$ P_i \in \{0,1\}$"></SPAN> means <SPAN CLASS="MATH"><IMG
 WIDTH="46" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.png"
 ALT="$ Flow_i$"></SPAN> can choose at most one path. <!-- MATH
 $max \ min \ R_i$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="93" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img31.png"
 ALT="$ max \ min \ R_i$"></SPAN> means <SPAN CLASS="MATH"><IMG
 WIDTH="46" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img32.png"
 ALT="$ Flow_{i}$"></SPAN>'s Interest sending rate should be max . The reason we set <!-- MATH
 $max \ min \ R_i$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="93" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img31.png"
 ALT="$ max \ min \ R_i$"></SPAN> is to achieve fairness between different flows.  If we do not set <!-- MATH
 $max \ min \ R_i$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="93" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img31.png"
 ALT="$ max \ min \ R_i$"></SPAN>, some flows may choose a min R to minimum the TFCT, and that will influence this flow's FCT. Sacrificing oneself to achieve the goal of minimum TFCT is unfair.

<P>
Routers send the updated forwarding-assistance and route information to the controller at the interval of <!-- MATH
 $\emph{RTT}_{\emph{avg}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ \emph{RTT}_{\emph{avg}}$"></SPAN>. The routers send back smart forwarding decision for each flow when it receives the router's updating information. The smart forwarding decision is based on the unit of flow, not the unit of each packet. So the overhead introduced by the controller's help is very limited compared with the whole volume that goes through the router. To timely reflect the change of network information to the controller, routers can change the sending interval, and that will raise the overhead. But the balance between the overhead and the accuracy of updating information can be adaptively controlled.

<P>

<H2><A NAME="SECTION00043000000000000000">
Stability analysis</A>
</H2>
The parameters <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> influence the stability and convergence of the system. As Eq. 2 shows, <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> influences how the bandwidth is use. If <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> is large then bandwidth will be occupied quickly. <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> influences how quickly that the packets in the queue can be drained. Obviously that large <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> can help the system to use the resource quickly. But large <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> will make the system become unstable, as the network is difficult to convergence.

<P>
To choose suitable <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> that make the system stable, we test under what <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> , the flow number can be estimated accurately. Once the flow number of the network can be accurately estimated, the Interest sending rate <SPAN  CLASS="textit">R(t)</SPAN> can also be estimated accurately, then the system will enter stable stage. So we choose the accuracy of estimating flow number as the stability evaluation criteria.

<P>
At first there are 10 flows in the network, and we test wether the flow number can accurately be estimated under different value of <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> . Fig. <A HREF="#fig-ab"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows that under such values the flow number can be accurately estimated. Fig. <A HREF="#fig-abwrong"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows that under these values the estimated flow number change heavily which means that the system is not stable. From Fig. <A HREF="#fig-ab"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>., we can find (0.2,1.5) is the most suitable value to estimate the flow number. Under this value, we test wether the system is still stable when the system changes. We set 5,10,15 and 20 flows in the network respectively. Fig. <A HREF="#fig-abflownum"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows that under different situation the flow number can also be accurately estimated when <!-- MATH
 $\alpha=0.2 \beta=1.5$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="107" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img33.png"
 ALT="$ \alpha=0.2 \beta=1.5$"></SPAN>. That means a fit value of <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> can make the system enter stable stage even when the system's situation changes.

<P>
From Fig. <A HREF="#fig-abwrong"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>., we find that when <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> close to 0.5, the system becomes unstable, and when it is larger than 0.5, the system becomes even more unstable. We think it is because large <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> makes the system react too radically to increase <SPAN  CLASS="textit">R(t)</SPAN>(when <SPAN  CLASS="textit">(C-S(t))</SPAN><SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img34.png"
 ALT="$ &gt;$"></SPAN>0) or decrease <SPAN  CLASS="textit">R(t)</SPAN>(when <SPAN  CLASS="textit">(C-S(t))</SPAN><SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img35.png"
 ALT="$ &lt;$"></SPAN>0). Radical reaction will make the system difficult to converge. From Fig. <A HREF="#fig-ab"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>., we find that when <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img35.png"
 ALT="$ &lt;$"></SPAN>0.2, the system will take longer time to accurately estimate the flow number. It is because small <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> makes the system increase or decrease <SPAN  CLASS="textit">R(t)</SPAN> conservatively, and that will result in longer time to convergence. When <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> smaller than 1.5, although the system can be stable, the estimated flow number is not accurate compared with <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> = 1.5. It is because small <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> can not drain the packets in the queue quickly enough. And that will result in inaccurate <SPAN  CLASS="textit">R(t)</SPAN> and flow number.

<P>
The key point of the stability analysis is that, for <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> we can choose a fit value to make the system stable. Even when the system changes, such as the flow number, RTT and bandwidth, the fit value can also make the system keep stable. Although now we can not prove the best value by theory, it is possible to choose a suitable value by experimental test. In our simulation, we set <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> = 0.2 and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> =1.5, according the analysis above.

<DIV ALIGN="CENTER"><A NAME="fig-ab"></A><A NAME="271"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Under such <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> the flow number can be accurately estimated.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="283" HEIGHT="207" ALIGN="BOTTOM" BORDER="0"
 SRC="img36.png"
 ALT="\includegraphics[width=2.5in]{ab-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<DIV ALIGN="CENTER"><A NAME="fig-abwrong"></A><A NAME="276"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Under such <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> the flow number can not be accurately estimated.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="283" HEIGHT="210" ALIGN="BOTTOM" BORDER="0"
 SRC="img37.png"
 ALT="\includegraphics[width=2.5in]{abwrong-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<DIV ALIGN="CENTER"><A NAME="fig-abflownum"></A><A NAME="281"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Stable <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> can make the network stable even when network situation changes.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="284" HEIGHT="216" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="\includegraphics[width=2.5in]{abflownum-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>


<P>

<H1><A NAME="SECTION00050000000000000000">
Simulation</A>
</H1>

<H2><A NAME="SECTION00051000000000000000">
Simulation setup</A>
</H2>
In this section, we study the performance of the smart explicitness congestion notification mechanism we proposed using ndnSim[<A
 HREF="main.html#ndnsimnet">17</A>] [<A
 HREF="main.html#ndnsim">18</A>].

<P>
Fig.<A HREF="#fig-topology"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows the network topology we use in the simulation. There are two topologies we use. One is bottleneck topology and the other one is mesh topology. In both network topologies, there are many consumers who send Interest into network and can get responding Data from the producer. The number of consumers is between [1,100], and each consumer requests Data with a same prefix (means they are a same flow). In the mesh network, consumers can get Data from three paths and each path's bottleneck bandwidth is different. Each link's capacity varies form [30,200]Mbps and the propagation delay of each hop is 10ms. The buffer in each node is production of delay-bandwidth. In the following figures, the bandwidth means the bottleneck's bandwidth.

<P>
We set the value of <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ \beta$"></SPAN> as 0.2 and 1.5. We compare our smart-ECN with ICP and ICP-shape. ICP is a TCP-style Interest control protocol in NDN. The Interest sending window is passively changed according the RTT and loss of Data, following the AIMD principle[<A
 HREF="main.html#ICP">2</A>]. ICP-shape also follows the AIMD principle but it discards the Interest instead Data when the routers sense congestion[<A
 HREF="main.html#improveshape">16</A>]. ICP-shape also sends NACK back to receiver if an Interest is shaped. NACK is a feedback information used to inform that the Interest has been discarded or there are not Data to response the Interest. The consumer should retransmit the same Interest when it receives a NACK.

<P>
Our simulation includes three parts. In the first part we evaluate the flow number estimating process, which we propose in Eq.4. In the second part, we will evaluate the ECN Interest sending rate mechanism using the bottleneck network topology. At last we will estimate the smart forwarding mechanism using the mesh network topology. The simulation result shows the number flows can be estimated accurately. Compared with ICP and ICP-shape, ECN Interest sending rate mechanism performance better in link utilization, packets dropping and flow complete time. Our smart forwarding mechanism has better TFCT compared with adaptive forwarding mechanism.

<DIV ALIGN="CENTER"><A NAME="fig-topology"></A><A NAME="529"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
The tow network topologies using in simulation.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV>
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<H2><A NAME="SECTION00052000000000000000">
The estimated flow number</A>
</H2>
By Eq. 4 <!-- MATH
 $Flow_{num}=\frac{C}{R(t-RTT_{avg})\ast{Size_{d}}}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="211" HEIGHT="36" ALIGN="MIDDLE" BORDER="0"
 SRC="img40.png"
 ALT="$ Flow_{num}=\frac{C}{R(t-RTT_{avg})\ast{Size_{d}}}$"></SPAN>, the flow number of the link can be estimated by the rate of this link. The size of Data can be estimated as the average size of the Data that goes through. Under the bottleneck network topology, at t=0, 10flows start. At t=10 more 10 flows start. And at t=20, 10 flows finish, remaining just 10 flows. From Fig.<A HREF="#fig-flownum"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. we can see that the flow number can be accurately estimated. Even when the flow number changes, the estimation can also converge.

<DIV ALIGN="CENTER"><A NAME="fig-flownum"></A><A NAME="540"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
The accuracy of estimated flow number.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="283" HEIGHT="216" ALIGN="BOTTOM" BORDER="0"
 SRC="img41.png"
 ALT="\includegraphics[width=2.5in]{flownum-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>

<H2><A NAME="SECTION00053000000000000000">
The performance of ECN Interest sending rate mechanism</A>
</H2>

<P>
We use bottleneck topology to estimate the ECN Interest sending rate mechanism. The ECN Interest sending rate is calculated based on the principle that the bandwidth should be ultimately used. The ICP and ICP-shape use the TCP-style window control way. TCP-style window control way uses the timeout-principle to sense the congestion, and once timeout, it cut the interest window to half. TCP-style window control also use the slow-start to send the Interest. These will waste a lot of bandwidth. As the Fig.<A HREF="#fig-linkuti"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows, ICP and ICP-shape waste bandwidth because of the slow start. The link utilization of ICP and ICP-shape is between 80%-90%. But even when the bottleneck link's bandwidth changes, the smart-ECN's bandwidth utilization always closes to 100%.

<DIV ALIGN="CENTER"><A NAME="fig-linkuti"></A><A NAME="547"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Bottleneck link utilization compared with ICP and ICP-shape when change the bottleneck bandwidth.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="283" HEIGHT="216" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="\includegraphics[width=2.5in]{utilization-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
Because the ECN Interest sending rate makes sure that the rate can not overflow the bandwidth, almost no packets(no matter Interest or Data) drop in ECN interest sending rate mechanism, as the Fig.<A HREF="#fig-drop"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows. ICP uses timeout as the signal to inform congestion, and timeout is caused by dropping Data. In ICP, once the link become congested, the only solution is to drop Data, so the number of dropping Data is very large,as Fig.<A HREF="#fig-drop"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows. The ICP-shape shapes Interest before congestion happens, so it can reduce the number of Data needed to be dropped because of congestion. But as the delay of sending back and the difficulty of estimating the congestion, there are still some dropping Data.

<DIV ALIGN="CENTER"><A NAME="fig-drop"></A><A NAME="554"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Bottleneck dropping packets compared with ICP and ICP-shape when change the bottleneck bandwidth.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="284" HEIGHT="208" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="\includegraphics[width=2.5in]{drop-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
As Eq.5 shows, the packets in the queue should do the utmost to be drained. This principle makes sure that in smart-ECN, the packets in the queue are always close to 0, as Fig.<A HREF="#fig-queue"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows. In ICP, to use the bandwidth effectively, the receivers always try to make the Interest window large until the Data fills up the queue and the Data is dropped, so the packets in the queue is large.  In ICP-shape , the router can shape Interest when it sense that congestion will happen. So in ICP-shape, the packets in queue is smaller than ICP,as Fig.<A HREF="#fig-queue"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows.

<DIV ALIGN="CENTER"><A NAME="fig-queue"></A><A NAME="561"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
 Bottleneck queuing packets compared with ICP and ICP-shape when change the bottleneck bandwidth.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="285" HEIGHT="205" ALIGN="BOTTOM" BORDER="0"
 SRC="img44.png"
 ALT="\includegraphics[width=2.5in]{queu-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
Fig.<A HREF="#fig-fct"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows the FCT of different flows. Flow complete time in NDN is defined as the time from when receiver send the first Interest until the receiver receives the last Data of the flow. The ECN Interest sending rate mechanism's link utilization is much higher than ICP. ECN Interest sending rate mechanism fairly applies bandwidth resource to all the flows, so even if the short flow can get fair bandwidth resource. So no matter short flows or long flows, their FCT is much better than ICP, as Fig.<A HREF="#fig-fct"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows. 

<DIV ALIGN="CENTER"><A NAME="fig-fct"></A><A NAME="568"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
 Smart-ECN's flow complete time compared with ICP.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="284" HEIGHT="214" ALIGN="BOTTOM" BORDER="0"
 SRC="img45.png"
 ALT="\includegraphics[width=2.5in]{fct-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>

<H2><A NAME="SECTION00054000000000000000">
Flow complete time compared with ICP</A>
</H2>

<P>
We demonstrate the effectiveness of smart adaptive forwarding mechanism using mesh network topology. The total bottleneck bandwidth means the sum of bottleneck bandwidth on all the available paths. Using the forwarding-assistance and route information, the smart adaptive forwarding mechanism can choose a network-wide best path. The adaptive mechanism chooses the best forwarding interface just by the next hop's link information. As the next hop link information can not reflect the whole path's information, the adaptive mechanism will sometimes choose a wrong path whose later link is shared by far more flows. The without-adaptive mechanism chooses the path just by the route information, similar with TCP/IP.  The without-adaptive mechanism can not change the forwarding interface according the network condition. As Fig.<A HREF="#fig-tfct"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="/usr/share/latex2html/icons/crossref.png"></A>. shows, under different total bandwidth, the smart adaptive forwarding's TFCT is much better than without-adaptive mechanism. As smart adaptive forwarding mechanism can choose a best path on the network-wide view, it's total flow complete time is even better than adaptive mechanism.

<DIV ALIGN="CENTER"><A NAME="fig-tfct"></A><A NAME="575"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure:</STRONG>
Total flow complete time compared with forwarding mechanisms.</CAPTION>
<TR><TD><DIV ALIGN="CENTER">

</DIV><IMG
 WIDTH="284" HEIGHT="217" ALIGN="BOTTOM" BORDER="0"
 SRC="img46.png"
 ALT="\includegraphics[width=2.5in]{adaptive-pic-cut.eps}">
<DIV ALIGN="CENTER">

</DIV></TD></TR>
</TABLE>
</DIV>


<P>

<H1><A NAME="SECTION00060000000000000000">
Related work</A>
</H1>
Some transport mechanisms have been proposed for NDN. Most of them is TCP-style. Some researchers use NDN's features, such as the NACK, to improve the TCP-style mechanism.

<P>
Receiver driven TCP-style. Different with TCP/IP¡¯s push principle, NDN is a pull-way architecture. So it is the receivers no longer the senders who dominant the traffic of network. Most of NDN transport mechanisms now proposed is receiver-driven. Receivers adjust its Interest sending window according to the RTT of the coming back Data, using the AIMD and slow start principle[<A
 HREF="main.html#TCP">9</A>], similar with traditional network. Contug[<A
 HREF="main.html#Contug">15</A>] is the first TCP-style receiver-driven mechanism in NDN, following the basic principle in TCP. It just changes the congestion-controller from sender to receiver.  In[<A
 HREF="main.html#Flow">13</A>], Sara, etc. use the prefix of the name to separate the traffic into different flows. Each flow uses TCP-like mechanism to control the congestion. Routers fairly share the bandwidth to each flow, and using optimal buffer algorithm to improve the performance. In NDN, in-network cache is available. T content can be get from different providers or routers. Different locations of content may result in multipath in transport layer. In [<A
 HREF="main.html#Multipath">14</A>], Givonaan, etc. deal with the multipath problem in NDN, using similar way as the MTCP.

<P>
Interest NACK. In NDN the Interest is much shorter than Data. Intuitively, it is much more ¡°resource-saving¡± if we drop Interest instead of Data when congestion happens. In HR-ICP[<A
 HREF="main.html#shape">5</A>], routers shape the Interest hop-by-hop to deal with or avoid congestion. Each router shapes Interest just by itself, according the bandwidth it can supply to coming Data. In [<A
 HREF="main.html#improveshape">16</A>] Wang, etc. improve the Interest shaping mechanism. Once an Interest is shaped, router sends NACK Interest back to the receiver to inform that congestion has happened. The NACK sending back to the receiver is useful information to inform the receiver that congestion happens. But it is still implicit information, does not inform the degree of congestion. The receiver simply cut half of the Interest sending window when it receives the congestion signal. That will reduce the link utilization as in TCP. And the shaping mechanism, no matter Interest or Data will cause retransmit. Retransmit will increase the flow complete time.

<P>
To fit the pull principle of NDN, all of these above mechanisms use the receiver to deal with the congestion. But they still follow the TCP's slow start and AIMD implicit congestion principle, such as RTT and time-out packet loss. They also have the low utilization and unfair problems, similar with TCP[<A
 HREF="main.html#NDNanalysis">12</A>]. 

<P>

<H1><A NAME="SECTION00070000000000000000">
Conclusion</A>
</H1>
In conclusion, we propose a ECN congestion control and a smart forwarding mechanism in NDN. Datas carry the ECN information to receivers. Receivers use ECN information to adjust its Interest sending rate. Under smart forwarding mechanism, routers choose a best forwarding interface using the SDN controller's network-view information. The ECN congestion control mechanism can ultimately use the link utilization and reduce the dropping packets. By joining the smart forwarding and ECN transport mechanism, the whole network resource can be effective used and total flow complete time can be reduced.

<P>
The future work will be focused on the theory proven of the system stability. In NDN, as the in-network cache, the Data's providers can be changed. That will influence the ECN information coming back the receiver and the RTT. We also want to analysis what would happen on such situation and how to make effective resolution for this.

<P>
 
<H2><A NAME="SECTION00080000000000000000">
Bibliography</A>
</H2><DL COMPACT><DD>
<P>
<P></P><DT><A NAME="NDN">1</A>
<DD>
V. Jacobson, D. K. Smetters, J. D. Thornton, M. F. Plass, N. H. Briggs,
and R. L. Braynard, ``Networking named content," in Proceedings of ACM
CoNEXT, 2009.
<P></P><DT><A NAME="ICP">2</A>
<DD>
G. Carofiglio, M. Gallo, and L. Muscariello, ``ICP: Design and evaluation
of an interest control protocol for content-centric networking," in Proc.
1st IEEE Int¡¯l Workshop on Emerging Design Choices in Name-Oriented
Networking, 2012.
<P></P><DT><A NAME="Adaptive">3</A>
<DD>
C. Yi, A. Afanasyev, L. Wang, B. Zhang, and L. Zhang, ``Adaptivd forwarding
in named data networking," in SIGCOMM Comput.Commun.Rev, 2012.
<P></P><DT><A NAME="CCTCP">4</A>
<DD>
L. Saino, C. Cocora, and G. Pavlou, ``CCTCP: A scalable receiver-driven
congestion control protocol for content centric networking," in Proc.IEEE ICC Int¡¯l Conference, 2013.
<P></P><DT><A NAME="shape">5</A>
<DD>
N. Rozhnova and S. Fdida, ``An effective hop-by-hop interest shaping
mechanism for ccn communications," in Proc.1st IEEE Int¡¯l Workshop on Emerging Design Choices in Name-Oriented Networking, 2012.
<P></P><DT><A NAME="SDN">6</A>
<DD>
A. Voellmy and J. Wang, ``Scalable software defined network controllers," in ACM SIGCOMM Computer Communication Review, 2012
<P></P><DT><A NAME="XCP">7</A>
<DD>
D. Katabi, M. Handley and C. Rohrs, ``Congestion control for high
bandwidth-delay product networks," in Proc.of ACM SIGCOMM,2002.
<P></P><DT><A NAME="RCP">8</A>
<DD>
N. Dukkipati, M. Kobayashi, R. Zhang-Shen, and N. McKeown, ``Processor
sharing flows in the internet," in IWQOS, 2006.
<P></P><DT><A NAME="TCP">9</A>
<DD>
V. Jacobson, ``Congestion avoidance and control," in SIGCOMM Comput.Commun.Rev, 1988.
<P></P><DT><A NAME="selfish">10</A>
<DD>
L. Qiu, Y. R. Yang, Y. Zhang, and S. Shenker, ``On selfish routing in internet-like environments," in Proc. of the ACM SIGCOMM,2003.
<P></P><DT><A NAME="ndnroute">11</A>
<DD>
R. Ahmed, and M. F. Bari, `` <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ \alpha$"></SPAN>Route: A Name Based Routing Scheme for Information Centric Networks," in Proc. of IEEE INFOCOM 2013.
<P></P><DT><A NAME="NDNanalysis">12</A>
<DD>
S. Braun, M. Monti, M. Sifalakis and C. Tschudin, ``An empirical study of
receiver-based AIMD flow control strategies for CCN," in IEEE ICCCN,2013.
<P></P><DT><A NAME="Flow">13</A>
<DD>
S. Oueslati, J. Roberts, and N. Sbihi, ``Flow-aware Traffic Control for
a  Content -Centric Network," in IEEE INFOCOM, 2012.
<P></P><DT><A NAME="Multipath">14</A>
<DD>
G. Carofiglio, M. Gallo, and L. Muscariello, ``Multipath congestion control in content-centric networks," in IEEE INFOCOM, 2013.
<P></P><DT><A NAME="Contug">15</A>
<DD>
S. Arianfar, P. Nikander, L. Eggert, and J. Ott, ``Contug: A receiver driven transport protocol for content-centric networks," in IEEE ICNP 2010 (Poster session),2010.
<P></P><DT><A NAME="improveshape">16</A>
<DD>
Y. G. Wang, N. Rozhnova, A. Narayanan, D. Oran, and I. Rhee, ``An improved hop-by-hop interest shaper for congestion control in named data networking," in Proc. Of ACM SIGCOMM ICN, 2013.
<P></P><DT><A NAME="ndnsimnet">17</A>
<DD>
http://ndnsim.net/
<P></P><DT><A NAME="ndnsim">18</A>
<DD>
A. Afanasyev, I. Moiseenko, and L. Zhang, ``ndnSIM: NDN simulator for NS-3," in NDN, Technical Report NDN-0005, 2012.

<P>
</DL>

<P>

<H1><A NAME="SECTION00090000000000000000">
About this document ...</A>
</H1>
 <STRONG>A smart explicitness congestion notification transport control mechanism for NDN</STRONG><P>
This document was generated using the
<A HREF="http://www.latex2html.org/"><STRONG>LaTeX</STRONG>2<tt>HTML</tt></A> translator Version 2008 (1.71)
<P>
Copyright &#169; 1993, 1994, 1995, 1996,
Nikos Drakos, 
Computer Based Learning Unit, University of Leeds.
<BR>Copyright &#169; 1997, 1998, 1999,
<A HREF="http://www.maths.mq.edu.au/~ross/">Ross Moore</A>, 
Mathematics Department, Macquarie University, Sydney.
<P>
The command line arguments were: <BR>
 <STRONG>latex2html</STRONG> <TT>-split 0 main.tex</TT>
<P>
The translation was initiated by alvin on 2014-02-26
<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<IMG WIDTH="81" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next_inactive"
 SRC="/usr/share/latex2html/icons/nx_grp_g.png"> 
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="/usr/share/latex2html/icons/up_g.png"> 
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="/usr/share/latex2html/icons/prev_g.png">   
<BR></DIV>
<!--End of Navigation Panel-->
<ADDRESS>
alvin
2014-02-26
</ADDRESS>
</BODY>
</HTML>
